{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resource usage of the StellarGraph class\n",
    "\n",
    "> This notebooks records the time and memory (both peak and long-term) required to construct a StellarGraph object for several datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbsphinx": "hidden",
    "tags": [
     "CloudRunner"
    ]
   },
   "source": [
    "<table><tr><td>Run the latest release of this notebook:</td><td><a href=\"https://mybinder.org/v2/gh/stellargraph/stellargraph/master?urlpath=lab/tree/demos/internal-developers/graph-resource-usage.ipynb\" alt=\"Open In Binder\" target=\"_parent\"><img src=\"https://mybinder.org/badge_logo.svg\"/></a></td><td><a href=\"https://colab.research.google.com/github/stellargraph/stellargraph/blob/master/demos/internal-developers/graph-resource-usage.ipynb\" alt=\"Open In Colab\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\"/></a></td></tr></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is aimed at helping contributors to the StellarGraph library itself understand how their changes affect the resource usage of the `StellarGraph` object.\n",
    "\n",
    "Various measures of resource usage for several \"real world\" graphs of various sizes are recorded:\n",
    "\n",
    "- time for construction\n",
    "- memory usage of the final `StellarGraph` object\n",
    "- peak memory usage during `StellarGraph` construction (both absolute, and additional compared to the raw input data)\n",
    "\n",
    "These are recorded both with explicit nodes (and node features if they exist), and implicit/inferred nodes.\n",
    "\n",
    "The memory usage is recorded end-to-end. That is, the recording starts from data on disk and continues until the `StellarGraph` object has been constructed and other data has been cleaned up. This is important for accurately recording the total memory usage, as NumPy arrays can often share data with existing arrays in memory and so retroactive or partial (starting from data in memory) analysis can miss significant amounts of data. The parsing code in `stellargraph.datasets` doesn't allow determining the memory usage of the intermediate nodes and edges input to the `StellarGraph` constructor, and so cannot be used here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "nbsphinx": "hidden",
    "tags": [
     "CloudRunner"
    ]
   },
   "outputs": [],
   "source": [
    "# install StellarGraph if running on Google Colab\n",
    "import sys\n",
    "if 'google.colab' in sys.modules:\n",
    "  %pip install -q stellargraph[demos]==1.1.0b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "nbsphinx": "hidden",
    "tags": [
     "VersionCheck"
    ]
   },
   "outputs": [],
   "source": [
    "# verify that we're using the correct version of StellarGraph for this notebook\n",
    "import stellargraph as sg\n",
    "\n",
    "try:\n",
    "    sg.utils.validate_notebook_version(\"1.1.0b\")\n",
    "except AttributeError:\n",
    "    raise ValueError(\n",
    "        f\"This notebook requires StellarGraph version 1.1.0b, but a different version {sg.__version__} is installed.  Please see <https://github.com/stellargraph/stellargraph/issues/1172>.\"\n",
    "    ) from None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import stellargraph as sg\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import gc\n",
    "import json\n",
    "import os\n",
    "import timeit\n",
    "import tempfile\n",
    "import tracemalloc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional reddit data\n",
    "\n",
    "The original GraphSAGE paper evaluated on a reddit dataset, available at <http://snap.stanford.edu/graphsage/#datasets>. This dataset is large (1.3GB compressed) and so there is not automatic download support for it. The following `reddit_path` variable controls whether and how the reddit dataset is included:\n",
    "\n",
    "- to ignore the dataset: set the variable to `None`\n",
    "- to include the dataset: download the dataset zip, decompress it, and set the variable to the decompressed directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "reddit_path = os.path.expanduser(\"~/data/reddit\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cora = sg.datasets.Cora()\n",
    "cora.download()\n",
    "\n",
    "cora_cites_path = os.path.join(cora.data_directory, \"cora.cites\")\n",
    "cora_content_path = os.path.join(cora.data_directory, \"cora.content\")\n",
    "cora_dtypes = {0: int, **{i: np.float32 for i in range(1, 1433 + 1)}}\n",
    "\n",
    "\n",
    "def cora_parts(include_nodes):\n",
    "    if include_nodes:\n",
    "        nodes = pd.read_csv(\n",
    "            cora_content_path,\n",
    "            header=None,\n",
    "            sep=\"\\t\",\n",
    "            index_col=0,\n",
    "            usecols=range(0, 1433 + 1),\n",
    "            dtype=cora_dtypes,\n",
    "            na_filter=False,\n",
    "        )\n",
    "    else:\n",
    "        nodes = None\n",
    "    edges = pd.read_csv(\n",
    "        cora_cites_path,\n",
    "        header=None,\n",
    "        sep=\"\\t\",\n",
    "        names=[\"source\", \"target\"],\n",
    "        dtype=int,\n",
    "        na_filter=False,\n",
    "    )\n",
    "    return nodes, edges, {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BlogCatalog3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "blogcatalog3 = sg.datasets.BlogCatalog3()\n",
    "blogcatalog3.download()\n",
    "\n",
    "blogcatalog3_edges = os.path.join(blogcatalog3.data_directory, \"edges.csv\")\n",
    "blogcatalog3_group_edges = os.path.join(blogcatalog3.data_directory, \"group-edges.csv\")\n",
    "blogcatalog3_groups = os.path.join(blogcatalog3.data_directory, \"groups.csv\")\n",
    "blogcatalog3_nodes = os.path.join(blogcatalog3.data_directory, \"nodes.csv\")\n",
    "\n",
    "\n",
    "def blogcatalog3_parts(include_nodes):\n",
    "    if include_nodes:\n",
    "        raw_nodes = pd.read_csv(blogcatalog3_nodes, header=None)[0]\n",
    "        raw_groups = pd.read_csv(blogcatalog3_groups, header=None)[0]\n",
    "        nodes = {\n",
    "            \"user\": pd.DataFrame(index=raw_nodes),\n",
    "            \"group\": pd.DataFrame(index=-raw_groups),\n",
    "        }\n",
    "    else:\n",
    "        nodes = None\n",
    "\n",
    "    edges = pd.read_csv(blogcatalog3_edges, header=None, names=[\"source\", \"target\"])\n",
    "\n",
    "    group_edges = pd.read_csv(\n",
    "        blogcatalog3_group_edges, header=None, names=[\"source\", \"target\"]\n",
    "    )\n",
    "    group_edges[\"target\"] *= -1\n",
    "    start = len(edges)\n",
    "    group_edges.index = range(start, start + len(group_edges))\n",
    "\n",
    "    edges = {\"friend\": edges, \"belongs\": group_edges}\n",
    "    return nodes, edges, {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FB15k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "fb15k = sg.datasets.FB15k()\n",
    "fb15k.download()\n",
    "fb15k_files = [\n",
    "    os.path.join(fb15k.data_directory, f\"freebase_mtr100_mte100-{x}.txt\")\n",
    "    for x in [\"train\", \"test\", \"valid\"]\n",
    "]\n",
    "\n",
    "\n",
    "def fb15k_parts(include_nodes, usecols=None):\n",
    "    loaded = [\n",
    "        pd.read_csv(\n",
    "            name,\n",
    "            header=None,\n",
    "            names=[\"source\", \"label\", \"target\"],\n",
    "            sep=\"\\t\",\n",
    "            dtype=str,\n",
    "            na_filter=False,\n",
    "            usecols=usecols,\n",
    "        )\n",
    "        for name in fb15k_files\n",
    "    ]\n",
    "    edges = pd.concat(loaded, ignore_index=True)\n",
    "\n",
    "    if include_nodes:\n",
    "        # infer the set of nodes manually, in a memory-minimal way\n",
    "        raw_nodes = set(edges.source)\n",
    "        raw_nodes.update(edges.target)\n",
    "        nodes = pd.DataFrame(index=raw_nodes)\n",
    "    else:\n",
    "        nodes = None\n",
    "\n",
    "    return nodes, edges, {\"edge_type_column\": \"label\"}\n",
    "\n",
    "\n",
    "def fb15k_no_edge_types_parts(include_nodes):\n",
    "    nodes, edges, _ = fb15k_parts(include_nodes, usecols=[\"source\", \"target\"])\n",
    "    return nodes, edges, {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reddit\n",
    "\n",
    "As discussed above, the reddit dataset is large and optional. It is also slow to parse, as the graph structure is a huge JSON file. Thus, we prepare the dataset by converting that JSON file into a NumPy edge list array, of shape `(num_edges, 2)`. This is significantly faster to load from disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 17.2 s, sys: 1.72 s, total: 18.9 s\n",
      "Wall time: 18.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# if requested, prepare the reddit dataset by saving the slow-to-read JSON to a temporary .npy file\n",
    "if reddit_path is not None:\n",
    "    reddit_graph_path = os.path.join(reddit_path, \"reddit-G.json\")\n",
    "    reddit_feats_path = os.path.join(reddit_path, \"reddit-feats.npy\")\n",
    "\n",
    "    with open(reddit_graph_path) as f:\n",
    "        reddit_g = json.load(f)\n",
    "    reddit_numpy_edges = np.array([[x[\"source\"], x[\"target\"]] for x in reddit_g[\"links\"]])\n",
    "    \n",
    "    reddit_edges_file = tempfile.NamedTemporaryFile(suffix=\".npy\")\n",
    "    np.save(reddit_edges_file, reddit_numpy_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reddit_parts(include_nodes):\n",
    "    if include_nodes:\n",
    "        raw_nodes = np.load(reddit_feats_path)\n",
    "        nodes = pd.DataFrame(raw_nodes)\n",
    "    else:\n",
    "        nodes = None\n",
    "\n",
    "    raw_edges = np.load(reddit_edges_file.name)\n",
    "    edges = pd.DataFrame(raw_edges, columns=[\"source\", \"target\"])\n",
    "    return nodes, edges, {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = {\n",
    "    \"Cora\": cora_parts,\n",
    "    \"BlogCatalog3\": blogcatalog3_parts,\n",
    "    \"FB15k (no edge types)\": fb15k_no_edge_types_parts,\n",
    "    \"FB15k\": fb15k_parts,\n",
    "}\n",
    "if reddit_path is not None:\n",
    "    datasets[\"reddit\"] = reddit_parts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measurement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mem_snapshot_diff(after, before):\n",
    "    \"\"\"Total memory difference between two tracemalloc.snapshot objects\"\"\"\n",
    "    return sum(elem.size_diff for elem in after.compare_to(before, \"lineno\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiIndex([(                       'graph',                    'nodes'),\n",
       "            (                       'graph',           'node feat size'),\n",
       "            (                       'graph',                    'edges'),\n",
       "            (              'explicit nodes',                     'time'),\n",
       "            (              'explicit nodes',                 'mem (SG)'),\n",
       "            (              'explicit nodes',            'peak mem (SG)'),\n",
       "            (              'explicit nodes', 'peak mem (SG above data)'),\n",
       "            (              'explicit nodes',               'mem (data)'),\n",
       "            (              'explicit nodes',          'peak mem (data)'),\n",
       "            ('inferred nodes (no features)',                     'time'),\n",
       "            ('inferred nodes (no features)',                 'mem (SG)'),\n",
       "            ('inferred nodes (no features)',            'peak mem (SG)'),\n",
       "            ('inferred nodes (no features)', 'peak mem (SG above data)'),\n",
       "            ('inferred nodes (no features)',               'mem (data)'),\n",
       "            ('inferred nodes (no features)',          'peak mem (data)')],\n",
       "           )"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# names of columns computed by the measurement code\n",
    "def measurement_columns(title):\n",
    "    names = [\n",
    "        \"time\",\n",
    "        \"mem (SG)\",\n",
    "        \"peak mem (SG)\",\n",
    "        \"peak mem (SG above data)\",\n",
    "        \"mem (data)\",\n",
    "        \"peak mem (data)\",\n",
    "    ]\n",
    "    return [(title, x) for x in names]\n",
    "\n",
    "\n",
    "columns = pd.MultiIndex.from_tuples(\n",
    "    [\n",
    "        (\"graph\", \"nodes\"),\n",
    "        (\"graph\", \"node feat size\"),\n",
    "        (\"graph\", \"edges\"),\n",
    "        *measurement_columns(\"explicit nodes\"),\n",
    "        *measurement_columns(\"inferred nodes (no features)\"),\n",
    "    ]\n",
    ")\n",
    "columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_time(f, include_nodes):\n",
    "    nodes, edges, args = f(include_nodes)\n",
    "    start = timeit.default_timer()\n",
    "    sg.StellarGraph(nodes, edges, **args)\n",
    "    end = timeit.default_timer()\n",
    "    return end - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_memory(f, include_nodes):\n",
    "    \"\"\"\n",
    "    Measure exactly what it takes to load the data.\n",
    "    \n",
    "    - the size of the original edge data (as a baseline)\n",
    "    - the size of the final graph\n",
    "    - the peak memory use of both\n",
    "    \n",
    "    This uses a similar technique to the 'allocation_benchmark' fixture in tests/test_utils/alloc.py.\n",
    "    \"\"\"\n",
    "    gc.collect()\n",
    "\n",
    "    tracemalloc.start()\n",
    "    snapshot_start = tracemalloc.take_snapshot()\n",
    "\n",
    "    nodes, edges, args = f(include_nodes)\n",
    "\n",
    "    gc.collect()\n",
    "    _, data_memory_peak = tracemalloc.get_traced_memory()\n",
    "    snapshot_data = tracemalloc.take_snapshot()\n",
    "\n",
    "    if include_nodes:\n",
    "        assert nodes is not None, f\n",
    "        sg_g = sg.StellarGraph(nodes, edges, **args)\n",
    "    else:\n",
    "        assert nodes is None, f\n",
    "        sg_g = sg.StellarGraph(edges=edges, **args)\n",
    "\n",
    "    # clean up the input data and anything else leftover, so that the snapshot\n",
    "    # includes only the long-lasting data: the StellarGraph.\n",
    "    del edges\n",
    "    del nodes\n",
    "    del args\n",
    "    gc.collect()\n",
    "\n",
    "    _, graph_memory_peak = tracemalloc.get_traced_memory()\n",
    "    snapshot_end = tracemalloc.take_snapshot()\n",
    "    tracemalloc.stop()\n",
    "\n",
    "    data_memory = mem_snapshot_diff(snapshot_data, snapshot_start)\n",
    "    graph_memory = mem_snapshot_diff(snapshot_end, snapshot_start)\n",
    "\n",
    "    return (\n",
    "        sg_g,\n",
    "        graph_memory,\n",
    "        graph_memory_peak,\n",
    "        graph_memory_peak - data_memory,\n",
    "        data_memory,\n",
    "        data_memory_peak,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure(f):\n",
    "    time_nodes = measure_time(f, include_nodes=True)\n",
    "    time_no_nodes = measure_time(f, include_nodes=False)\n",
    "\n",
    "    sg_g, *mem_nodes = measure_memory(f, include_nodes=True)\n",
    "    _, *mem_no_nodes = measure_memory(f, include_nodes=False)\n",
    "\n",
    "    feat_sizes = sg_g.node_feature_sizes()\n",
    "    try:\n",
    "        feat_sizes = feat_sizes[sg_g.unique_node_type()]\n",
    "    except ValueError:\n",
    "        pass\n",
    "\n",
    "    return [\n",
    "        sg_g.number_of_nodes(),\n",
    "        feat_sizes,\n",
    "        sg_g.number_of_edges(),\n",
    "        time_nodes,\n",
    "        *mem_nodes,\n",
    "        time_no_nodes,\n",
    "        *mem_no_nodes,\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 24.2 s, sys: 5.33 s, total: 29.5 s\n",
      "Wall time: 29.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "recorded = [measure(f) for f in datasets.values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">graph</th>\n",
       "      <th colspan=\"6\" halign=\"left\">explicit nodes</th>\n",
       "      <th colspan=\"6\" halign=\"left\">inferred nodes (no features)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>nodes</th>\n",
       "      <th>node feat size</th>\n",
       "      <th>edges</th>\n",
       "      <th>time</th>\n",
       "      <th>mem (SG)</th>\n",
       "      <th>peak mem (SG)</th>\n",
       "      <th>peak mem (SG above data)</th>\n",
       "      <th>mem (data)</th>\n",
       "      <th>peak mem (data)</th>\n",
       "      <th>time</th>\n",
       "      <th>mem (SG)</th>\n",
       "      <th>peak mem (SG)</th>\n",
       "      <th>peak mem (SG above data)</th>\n",
       "      <th>mem (data)</th>\n",
       "      <th>peak mem (data)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Cora</th>\n",
       "      <td>2708</td>\n",
       "      <td>1433</td>\n",
       "      <td>5429</td>\n",
       "      <td>0.030567</td>\n",
       "      <td>15616268</td>\n",
       "      <td>46772250</td>\n",
       "      <td>31088362</td>\n",
       "      <td>15683888</td>\n",
       "      <td>31993944</td>\n",
       "      <td>0.006995</td>\n",
       "      <td>94284</td>\n",
       "      <td>405221</td>\n",
       "      <td>314961</td>\n",
       "      <td>90260</td>\n",
       "      <td>197784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BlogCatalog3</th>\n",
       "      <td>10351</td>\n",
       "      <td>{'user': 0, 'group': 0}</td>\n",
       "      <td>348459</td>\n",
       "      <td>0.045832</td>\n",
       "      <td>6070473</td>\n",
       "      <td>18996022</td>\n",
       "      <td>13326461</td>\n",
       "      <td>5669561</td>\n",
       "      <td>10806213</td>\n",
       "      <td>0.041768</td>\n",
       "      <td>6069969</td>\n",
       "      <td>18996934</td>\n",
       "      <td>13414822</td>\n",
       "      <td>5582112</td>\n",
       "      <td>10711888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FB15k (no edge types)</th>\n",
       "      <td>14951</td>\n",
       "      <td>0</td>\n",
       "      <td>592213</td>\n",
       "      <td>0.152511</td>\n",
       "      <td>6398752</td>\n",
       "      <td>37222062</td>\n",
       "      <td>21542696</td>\n",
       "      <td>15679366</td>\n",
       "      <td>25831073</td>\n",
       "      <td>0.244645</td>\n",
       "      <td>6407984</td>\n",
       "      <td>37232686</td>\n",
       "      <td>21678832</td>\n",
       "      <td>15553854</td>\n",
       "      <td>25050234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FB15k</th>\n",
       "      <td>14951</td>\n",
       "      <td>0</td>\n",
       "      <td>592213</td>\n",
       "      <td>0.776939</td>\n",
       "      <td>12081749</td>\n",
       "      <td>57260717</td>\n",
       "      <td>36358643</td>\n",
       "      <td>20902074</td>\n",
       "      <td>35791845</td>\n",
       "      <td>0.867180</td>\n",
       "      <td>12072501</td>\n",
       "      <td>57252173</td>\n",
       "      <td>36475611</td>\n",
       "      <td>20776562</td>\n",
       "      <td>35011006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reddit</th>\n",
       "      <td>232965</td>\n",
       "      <td>602</td>\n",
       "      <td>11606919</td>\n",
       "      <td>4.826181</td>\n",
       "      <td>712113351</td>\n",
       "      <td>3551638965</td>\n",
       "      <td>2243953025</td>\n",
       "      <td>1307685940</td>\n",
       "      <td>1307694919</td>\n",
       "      <td>1.078231</td>\n",
       "      <td>153909433</td>\n",
       "      <td>624260822</td>\n",
       "      <td>438546030</td>\n",
       "      <td>185714792</td>\n",
       "      <td>185723195</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        graph                                     \\\n",
       "                        nodes           node feat size     edges   \n",
       "Cora                     2708                     1433      5429   \n",
       "BlogCatalog3            10351  {'user': 0, 'group': 0}    348459   \n",
       "FB15k (no edge types)   14951                        0    592213   \n",
       "FB15k                   14951                        0    592213   \n",
       "reddit                 232965                      602  11606919   \n",
       "\n",
       "                      explicit nodes                           \\\n",
       "                                time   mem (SG) peak mem (SG)   \n",
       "Cora                        0.030567   15616268      46772250   \n",
       "BlogCatalog3                0.045832    6070473      18996022   \n",
       "FB15k (no edge types)       0.152511    6398752      37222062   \n",
       "FB15k                       0.776939   12081749      57260717   \n",
       "reddit                      4.826181  712113351    3551638965   \n",
       "\n",
       "                                                                            \\\n",
       "                      peak mem (SG above data)  mem (data) peak mem (data)   \n",
       "Cora                                  31088362    15683888        31993944   \n",
       "BlogCatalog3                          13326461     5669561        10806213   \n",
       "FB15k (no edge types)                 21542696    15679366        25831073   \n",
       "FB15k                                 36358643    20902074        35791845   \n",
       "reddit                              2243953025  1307685940      1307694919   \n",
       "\n",
       "                      inferred nodes (no features)                           \\\n",
       "                                              time   mem (SG) peak mem (SG)   \n",
       "Cora                                      0.006995      94284        405221   \n",
       "BlogCatalog3                              0.041768    6069969      18996934   \n",
       "FB15k (no edge types)                     0.244645    6407984      37232686   \n",
       "FB15k                                     0.867180   12072501      57252173   \n",
       "reddit                                    1.078231  153909433     624260822   \n",
       "\n",
       "                                                                           \n",
       "                      peak mem (SG above data) mem (data) peak mem (data)  \n",
       "Cora                                    314961      90260          197784  \n",
       "BlogCatalog3                          13414822    5582112        10711888  \n",
       "FB15k (no edge types)                 21678832   15553854        25050234  \n",
       "FB15k                                 36475611   20776562        35011006  \n",
       "reddit                               438546030  185714792       185723195  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw = pd.DataFrame(recorded, columns=columns, index=datasets.keys())\n",
    "raw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pretty results\n",
    "\n",
    "This shows the results in a prettier way, such as memory in MiB instead of bytes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">graph</th>\n",
       "      <th colspan=\"6\" halign=\"left\">explicit nodes</th>\n",
       "      <th colspan=\"6\" halign=\"left\">inferred nodes (no features)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>nodes</th>\n",
       "      <th>node feat size</th>\n",
       "      <th>edges</th>\n",
       "      <th>time</th>\n",
       "      <th>mem (SG)</th>\n",
       "      <th>peak mem (SG)</th>\n",
       "      <th>peak mem (SG above data)</th>\n",
       "      <th>mem (data)</th>\n",
       "      <th>peak mem (data)</th>\n",
       "      <th>time</th>\n",
       "      <th>mem (SG)</th>\n",
       "      <th>peak mem (SG)</th>\n",
       "      <th>peak mem (SG above data)</th>\n",
       "      <th>mem (data)</th>\n",
       "      <th>peak mem (data)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Cora</th>\n",
       "      <td>2708</td>\n",
       "      <td>1433</td>\n",
       "      <td>5429</td>\n",
       "      <td>0.030567</td>\n",
       "      <td>14.892834</td>\n",
       "      <td>44.605494</td>\n",
       "      <td>29.648172</td>\n",
       "      <td>14.957321</td>\n",
       "      <td>30.511803</td>\n",
       "      <td>0.006995</td>\n",
       "      <td>0.089916</td>\n",
       "      <td>0.386449</td>\n",
       "      <td>0.300370</td>\n",
       "      <td>0.086079</td>\n",
       "      <td>0.188622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BlogCatalog3</th>\n",
       "      <td>10351</td>\n",
       "      <td>{'user': 0, 'group': 0}</td>\n",
       "      <td>348459</td>\n",
       "      <td>0.045832</td>\n",
       "      <td>5.789254</td>\n",
       "      <td>18.116018</td>\n",
       "      <td>12.709104</td>\n",
       "      <td>5.406915</td>\n",
       "      <td>10.305608</td>\n",
       "      <td>0.041768</td>\n",
       "      <td>5.788774</td>\n",
       "      <td>18.116888</td>\n",
       "      <td>12.793371</td>\n",
       "      <td>5.323517</td>\n",
       "      <td>10.215652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FB15k (no edge types)</th>\n",
       "      <td>14951</td>\n",
       "      <td>0</td>\n",
       "      <td>592213</td>\n",
       "      <td>0.152511</td>\n",
       "      <td>6.102325</td>\n",
       "      <td>35.497725</td>\n",
       "      <td>20.544716</td>\n",
       "      <td>14.953009</td>\n",
       "      <td>24.634431</td>\n",
       "      <td>0.244645</td>\n",
       "      <td>6.111130</td>\n",
       "      <td>35.507856</td>\n",
       "      <td>20.674545</td>\n",
       "      <td>14.833311</td>\n",
       "      <td>23.889765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FB15k</th>\n",
       "      <td>14951</td>\n",
       "      <td>0</td>\n",
       "      <td>592213</td>\n",
       "      <td>0.776939</td>\n",
       "      <td>11.522054</td>\n",
       "      <td>54.608075</td>\n",
       "      <td>34.674304</td>\n",
       "      <td>19.933771</td>\n",
       "      <td>34.133763</td>\n",
       "      <td>0.867180</td>\n",
       "      <td>11.513234</td>\n",
       "      <td>54.599927</td>\n",
       "      <td>34.785853</td>\n",
       "      <td>19.814074</td>\n",
       "      <td>33.389097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reddit</th>\n",
       "      <td>232965</td>\n",
       "      <td>602</td>\n",
       "      <td>11606919</td>\n",
       "      <td>4.826181</td>\n",
       "      <td>679.124213</td>\n",
       "      <td>3387.106862</td>\n",
       "      <td>2140.000367</td>\n",
       "      <td>1247.106495</td>\n",
       "      <td>1247.115058</td>\n",
       "      <td>1.078231</td>\n",
       "      <td>146.779473</td>\n",
       "      <td>595.341513</td>\n",
       "      <td>418.230085</td>\n",
       "      <td>177.111427</td>\n",
       "      <td>177.119441</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        graph                                     \\\n",
       "                        nodes           node feat size     edges   \n",
       "Cora                     2708                     1433      5429   \n",
       "BlogCatalog3            10351  {'user': 0, 'group': 0}    348459   \n",
       "FB15k (no edge types)   14951                        0    592213   \n",
       "FB15k                   14951                        0    592213   \n",
       "reddit                 232965                      602  11606919   \n",
       "\n",
       "                      explicit nodes                            \\\n",
       "                                time    mem (SG) peak mem (SG)   \n",
       "Cora                        0.030567   14.892834     44.605494   \n",
       "BlogCatalog3                0.045832    5.789254     18.116018   \n",
       "FB15k (no edge types)       0.152511    6.102325     35.497725   \n",
       "FB15k                       0.776939   11.522054     54.608075   \n",
       "reddit                      4.826181  679.124213   3387.106862   \n",
       "\n",
       "                                                                             \\\n",
       "                      peak mem (SG above data)   mem (data) peak mem (data)   \n",
       "Cora                                 29.648172    14.957321       30.511803   \n",
       "BlogCatalog3                         12.709104     5.406915       10.305608   \n",
       "FB15k (no edge types)                20.544716    14.953009       24.634431   \n",
       "FB15k                                34.674304    19.933771       34.133763   \n",
       "reddit                             2140.000367  1247.106495     1247.115058   \n",
       "\n",
       "                      inferred nodes (no features)                            \\\n",
       "                                              time    mem (SG) peak mem (SG)   \n",
       "Cora                                      0.006995    0.089916      0.386449   \n",
       "BlogCatalog3                              0.041768    5.788774     18.116888   \n",
       "FB15k (no edge types)                     0.244645    6.111130     35.507856   \n",
       "FB15k                                     0.867180   11.513234     54.599927   \n",
       "reddit                                    1.078231  146.779473    595.341513   \n",
       "\n",
       "                                                                            \n",
       "                      peak mem (SG above data)  mem (data) peak mem (data)  \n",
       "Cora                                  0.300370    0.086079        0.188622  \n",
       "BlogCatalog3                         12.793371    5.323517       10.215652  \n",
       "FB15k (no edge types)                20.674545   14.833311       23.889765  \n",
       "FB15k                                34.785853   19.814074       33.389097  \n",
       "reddit                              418.230085  177.111427      177.119441  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mem_columns = raw.columns[[\"mem\" in x[1] for x in raw.columns]]\n",
    "\n",
    "memory_mib = raw.copy()\n",
    "memory_mib[mem_columns] /= 2 ** 20\n",
    "memory_mib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbsphinx": "hidden",
    "tags": [
     "CloudRunner"
    ]
   },
   "source": [
    "<table><tr><td>Run the latest release of this notebook:</td><td><a href=\"https://mybinder.org/v2/gh/stellargraph/stellargraph/master?urlpath=lab/tree/demos/internal-developers/graph-resource-usage.ipynb\" alt=\"Open In Binder\" target=\"_parent\"><img src=\"https://mybinder.org/badge_logo.svg\"/></a></td><td><a href=\"https://colab.research.google.com/github/stellargraph/stellargraph/blob/master/demos/internal-developers/graph-resource-usage.ipynb\" alt=\"Open In Colab\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\"/></a></td></tr></table>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
